{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "spark=SparkSession.builder.getOrCreate()"
      ],
      "metadata": {
        "id": "eBMK3Tpd1mx1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions as F\n",
        "from pyspark.sql.types import *"
      ],
      "metadata": {
        "id": "ZuN5Ep-Z1q6F"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "uvpU55HR1kBm"
      },
      "outputs": [],
      "source": [
        "orders_data = [\n",
        "(\"O001\",\"Delhi \",\"Laptop\",\"45000\",\"2024-01-05\",\"Completed\"),\n",
        "(\"O002\",\"Mumbai\",\"Mobile \",\"32000\",\"05/01/2024\",\"Completed\"),\n",
        "(\"O003\",\"Bangalore\",\"Tablet\",\"30000\",\"2024/01/06\",\"Completed\"),\n",
        "(\"O004\",\"Delhi\",\"Laptop\",\"\",\"2024-01-07\",\"Cancelled\"),\n",
        "(\"O005\",\"Mumbai\",\"Mobile\",\"invalid\",\"2024-01-08\",\"Completed\"),\n",
        "(\"O006\",\"Chennai\",\"Tablet\",None,\"2024-01-08\",\"Completed\"),\n",
        "(\"O007\",\"Delhi\",\"Laptop\",\"47000\",\"09-01-2024\",\"Completed\"),\n",
        "(\"O008\",\"Bangalore\",\"Mobile\",\"28000\",\"2024-01-09\",\"Completed\"),\n",
        "(\"O009\",\"Mumbai\",\"Laptop\",\"55000\",\"2024-01-10\",\"Completed\"),\n",
        "(\"O009\",\"Mumbai\",\"Laptop\",\"55000\",\"2024-01-10\",\"Completed\")\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Define ne an explicit schema \\\n",
        ". Create a DataFrame using the schema \\\n",
        ". Print schema and validate data types"
      ],
      "metadata": {
        "id": "_o2x1Kwm_Ee0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#columns=[\"order_id\",\"city\" ,\"product\" ,\"amount\" ,\"order_date\" ,\"status\"]\n",
        "schema = StructType([\n",
        "    StructField(\"order_id\", StringType(), False),\n",
        "    StructField(\"city\", StringType(), True),\n",
        "    StructField(\"product\", StringType(), True),\n",
        "    StructField(\"amount\", StringType(), True),\n",
        "    StructField(\"order_date\", StringType(), True),\n",
        "    StructField(\"status\", StringType(), True),\n",
        "])\n",
        "orders_df_raw=spark.createDataFrame(orders_data,schema)"
      ],
      "metadata": {
        "id": "RpXgbh5j1mRC"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df_raw.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHkNSRXm2t6b",
        "outputId": "194f6a20-9457-4601-b436-9411c63ca63c"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-------+------+----------+---------+\n",
            "|order_id|     city|product|amount|order_date|   status|\n",
            "+--------+---------+-------+------+----------+---------+\n",
            "|    O001|    Delhi| Laptop| 45000|2024-01-05|Completed|\n",
            "|    O002|   Mumbai| Mobile| 32000|2024-01-05|Completed|\n",
            "|    O003|Bangalore| Tablet| 30000|2024-01-06|Completed|\n",
            "|    O004|    Delhi| Laptop|  NULL|2024-01-07|Cancelled|\n",
            "|    O005|   Mumbai| Mobile|  NULL|2024-01-08|Completed|\n",
            "|    O006|  Chennai| Tablet|  NULL|2024-01-08|Completed|\n",
            "|    O007|    Delhi| Laptop| 47000|2024-01-09|Completed|\n",
            "|    O008|Bangalore| Mobile| 28000|2024-01-09|Completed|\n",
            "|    O009|   Mumbai| Laptop| 55000|2024-01-10|Completed|\n",
            "|    O009|   Mumbai| Laptop| 55000|2024-01-10|Completed|\n",
            "+--------+---------+-------+------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df_raw.printSchema()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UD4N6MMc2v7g",
        "outputId": "f4bb33f1-9b11-43bb-b216-97bb4307a71d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- order_id: string (nullable = false)\n",
            " |-- city: string (nullable = true)\n",
            " |-- product: string (nullable = true)\n",
            " |-- amount: integer (nullable = true)\n",
            " |-- order_date: date (nullable = true)\n",
            " |-- status: string (nullable = true)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Convert amount to IntegerType"
      ],
      "metadata": {
        "id": "uoyKXSPE_VLk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df_raw = orders_df_raw.withColumn(\n",
        "    \"amount\",\n",
        "    F.when(F.col(\"amount\").rlike(\"^[0-9]+$\"), F.col(\"amount\").cast(\"int\"))\n",
        "     .otherwise(None)\n",
        ")"
      ],
      "metadata": {
        "id": "KSSc06PW29cl"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df_raw = orders_df_raw.withColumn(\n",
        "    \"order_date\",\n",
        "    F.coalesce(\n",
        "        F.to_date(\"order_date\", \"yyyy-MM-dd\"),\n",
        "        F.to_date(\"order_date\", \"dd-MM-yyyy\"),\n",
        "        F.to_date(\"order_date\", \"dd/MM/yyyy\"),\n",
        "        F.to_date(\"order_date\", \"yyyy/MM/dd\")\n",
        "    )\n",
        ")"
      ],
      "metadata": {
        "id": "XQ74Rkeh3TJa"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark.conf.set(\"spark.sql.ansi.enabled\", \"false\")"
      ],
      "metadata": {
        "id": "Uc6WuajJ4ZxQ"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Trim all string columns"
      ],
      "metadata": {
        "id": "xgdr8962_Ooa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df_raw = orders_df_raw.withColumn(\n",
        "    \"city\",\n",
        "    F.initcap(F.trim(F.col(\"city\")))\n",
        ")\n",
        "orders_df_raw = orders_df_raw.withColumn(\n",
        "    \"product\",\n",
        "    F.initcap(F.trim(F.col(\"product\")))\n",
        ")\n",
        "orders_df_raw = orders_df_raw.withColumn(\n",
        "    \"status\",\n",
        "    F.initcap(F.trim(F.col(\"status\")))\n",
        ")"
      ],
      "metadata": {
        "id": "k8B6cmVg4dTI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "handle null values"
      ],
      "metadata": {
        "id": "YcFJNrSJ_ZrH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df_clean = orders_df_raw.na.drop(subset=[\"amount\"])"
      ],
      "metadata": {
        "id": "UuAHiFx-480y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remove duplicate orders\n"
      ],
      "metadata": {
        "id": "GwFdSMy1_iL2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df_clean = (\n",
        "    orders_df_clean.dropDuplicates([\"order_id\"])\n",
        ")"
      ],
      "metadata": {
        "id": "vdbPxW535yt4"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "orders_df_clean.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYToO7Rf5j4I",
        "outputId": "7e7c3771-94de-49dc-dcb1-db91fe6aa8a8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-------+------+----------+---------+\n",
            "|order_id|     city|product|amount|order_date|   status|\n",
            "+--------+---------+-------+------+----------+---------+\n",
            "|    O001|    Delhi| Laptop| 45000|2024-01-05|Completed|\n",
            "|    O002|   Mumbai| Mobile| 32000|2024-01-05|Completed|\n",
            "|    O003|Bangalore| Tablet| 30000|2024-01-06|Completed|\n",
            "|    O007|    Delhi| Laptop| 47000|2024-01-09|Completed|\n",
            "|    O008|Bangalore| Mobile| 28000|2024-01-09|Completed|\n",
            "|    O009|   Mumbai| Laptop| 55000|2024-01-10|Completed|\n",
            "+--------+---------+-------+------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Keep only Completed orders"
      ],
      "metadata": {
        "id": "e79UkiAe_k0Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completed_orders=orders_df_clean.filter(F.col(\"status\")==\"Completed\")"
      ],
      "metadata": {
        "id": "cAH9eqGd5lyE"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completed_orders.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LLlSUmxf6CLe",
        "outputId": "4b262eb9-006d-499a-9da4-2e01cb530928"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+---------+-------+------+----------+---------+\n",
            "|order_id|     city|product|amount|order_date|   status|\n",
            "+--------+---------+-------+------+----------+---------+\n",
            "|    O001|    Delhi| Laptop| 45000|2024-01-05|Completed|\n",
            "|    O002|   Mumbai| Mobile| 32000|2024-01-05|Completed|\n",
            "|    O003|Bangalore| Tablet| 30000|2024-01-06|Completed|\n",
            "|    O007|    Delhi| Laptop| 47000|2024-01-09|Completed|\n",
            "|    O008|Bangalore| Mobile| 28000|2024-01-09|Completed|\n",
            "|    O009|   Mumbai| Laptop| 55000|2024-01-10|Completed|\n",
            "+--------+---------+-------+------+----------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Total revenue per city"
      ],
      "metadata": {
        "id": "j6tvnz8d6UgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_per_city = (\n",
        "    completed_orders\n",
        "    .groupBy(\"city\")\n",
        "    .agg(F.sum(\"amount\").alias(\"total_revenue\"))\n",
        ")\n",
        "revenue_per_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ao4ZVa0S6GK5",
        "outputId": "d73f5c12-00c4-4aea-a7c4-e7ff4addacb5"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|     city|total_revenue|\n",
            "+---------+-------------+\n",
            "|Bangalore|        58000|\n",
            "|   Mumbai|        87000|\n",
            "|    Delhi|        92000|\n",
            "+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Total revenue per product"
      ],
      "metadata": {
        "id": "n2EmLY8p6lwM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_per_product = (\n",
        "    completed_orders\n",
        "    .groupBy(\"product\")\n",
        "    .agg(F.sum(\"amount\").alias(\"total_revenue\"))\n",
        ")\n",
        "revenue_per_product.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ym9bXAHK6fRy",
        "outputId": "75c2e872-a435-4f57-9c7f-56568e92d8a2"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-------------+\n",
            "|product|total_revenue|\n",
            "+-------+-------------+\n",
            "| Laptop|       147000|\n",
            "| Mobile|        60000|\n",
            "| Tablet|        30000|\n",
            "+-------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Average order value per city"
      ],
      "metadata": {
        "id": "uYtx4e1Z64A-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "average_order_per_city = (\n",
        "    completed_orders\n",
        "    .groupBy(\"city\")\n",
        "    .agg(F.avg(\"amount\").alias(\"average_order\"))\n",
        ")\n",
        "average_order_per_city.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5G3Rt5463ui",
        "outputId": "c3f5a383-62d4-4958-970b-fc5ad86c1b25"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|     city|average_order|\n",
            "+---------+-------------+\n",
            "|Bangalore|      29000.0|\n",
            "|   Mumbai|      43500.0|\n",
            "|    Delhi|      46000.0|\n",
            "+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rank cities by total revenue"
      ],
      "metadata": {
        "id": "AiXIWAPA7JFX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.window import Window\n",
        "city_rank_window = Window.orderBy(F.col(\"total_revenue\").desc())\n",
        "\n",
        "ranked_cities = (\n",
        "    revenue_per_city\n",
        "    .withColumn(\"city_rank\", F.rank().over(city_rank_window))\n",
        ")\n",
        "top_city=ranked_cities.first()\n",
        "ranked_cities.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpC70ZWT6sn7",
        "outputId": "5e3a6349-ffd7-4e75-c2b4-2e5fbd12051f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+---------+\n",
            "|     city|total_revenue|city_rank|\n",
            "+---------+-------------+---------+\n",
            "|    Delhi|        92000|        1|\n",
            "|   Mumbai|        87000|        2|\n",
            "|Bangalore|        58000|        3|\n",
            "+---------+-------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identify top-performing city"
      ],
      "metadata": {
        "id": "zcB06WsV7414"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(top_city[\"city\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "USGRxBp37ZIf",
        "outputId": "046b2255-d3ea-4731-814a-afedbc136f09"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Delhi\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ". Cache the cleaned DataFrame\n",
        ". Run two aggregations and observe behavior\n",
        ". Use explain(True) to inspect the plan"
      ],
      "metadata": {
        "id": "kZ5vHwBL8IIE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "completed_orders.cache()\n",
        "completed_orders.count()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V563F3pm8Cxb",
        "outputId": "f277b110-96e7-43bc-94fd-72014fb62d49"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_per_city2 = (\n",
        "    completed_orders\n",
        "    .groupBy(\"city\")\n",
        "    .agg(F.sum(\"amount\").alias(\"total_revenue\"))\n",
        ")\n"
      ],
      "metadata": {
        "id": "J9_MTknV8bXp"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_per_city2.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GICwAxJ08hxy",
        "outputId": "deee03ca-904d-422e-ba19-dd682562e84a"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+\n",
            "|     city|total_revenue|\n",
            "+---------+-------------+\n",
            "|   Mumbai|        87000|\n",
            "|    Delhi|        92000|\n",
            "|Bangalore|        58000|\n",
            "+---------+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "revenue_per_city2.explain(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3RVJBtAJ8sfI",
        "outputId": "1d300139-1f11-4217-bcb2-5e9f8b154c31"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "== Parsed Logical Plan ==\n",
            "'Aggregate ['city], ['city, 'sum('amount) AS total_revenue#1060]\n",
            "+- Filter (status#119 = Completed)\n",
            "   +- Deduplicate [order_id#90]\n",
            "      +- Filter atleastnnonnulls(1, amount#96)\n",
            "         +- Project [order_id#90, city#117, product#118, amount#96, order_date#97, initcap(trim(status#95, None)) AS status#119]\n",
            "            +- Project [order_id#90, city#117, initcap(trim(product#92, None)) AS product#118, amount#96, order_date#97, status#95]\n",
            "               +- Project [order_id#90, initcap(trim(city#91, None)) AS city#117, product#92, amount#96, order_date#97, status#95]\n",
            "                  +- Project [order_id#90, city#91, product#92, amount#96, coalesce(to_date(order_date#94, Some(yyyy-MM-dd), Some(Etc/UTC), false), to_date(order_date#94, Some(dd-MM-yyyy), Some(Etc/UTC), false), to_date(order_date#94, Some(dd/MM/yyyy), Some(Etc/UTC), false), to_date(order_date#94, Some(yyyy/MM/dd), Some(Etc/UTC), false)) AS order_date#97, status#95]\n",
            "                     +- Project [order_id#90, city#91, product#92, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) ELSE cast(null as int) END AS amount#96, order_date#94, status#95]\n",
            "                        +- LogicalRDD [order_id#90, city#91, product#92, amount#93, order_date#94, status#95], false\n",
            "\n",
            "== Analyzed Logical Plan ==\n",
            "city: string, total_revenue: bigint\n",
            "Aggregate [city#117], [city#117, sum(amount#96) AS total_revenue#1060L]\n",
            "+- Filter (status#119 = Completed)\n",
            "   +- Deduplicate [order_id#90]\n",
            "      +- Filter atleastnnonnulls(1, amount#96)\n",
            "         +- Project [order_id#90, city#117, product#118, amount#96, order_date#97, initcap(trim(status#95, None)) AS status#119]\n",
            "            +- Project [order_id#90, city#117, initcap(trim(product#92, None)) AS product#118, amount#96, order_date#97, status#95]\n",
            "               +- Project [order_id#90, initcap(trim(city#91, None)) AS city#117, product#92, amount#96, order_date#97, status#95]\n",
            "                  +- Project [order_id#90, city#91, product#92, amount#96, coalesce(to_date(order_date#94, Some(yyyy-MM-dd), Some(Etc/UTC), false), to_date(order_date#94, Some(dd-MM-yyyy), Some(Etc/UTC), false), to_date(order_date#94, Some(dd/MM/yyyy), Some(Etc/UTC), false), to_date(order_date#94, Some(yyyy/MM/dd), Some(Etc/UTC), false)) AS order_date#97, status#95]\n",
            "                     +- Project [order_id#90, city#91, product#92, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) ELSE cast(null as int) END AS amount#96, order_date#94, status#95]\n",
            "                        +- LogicalRDD [order_id#90, city#91, product#92, amount#93, order_date#94, status#95], false\n",
            "\n",
            "== Optimized Logical Plan ==\n",
            "Aggregate [city#117], [city#117, sum(amount#96) AS total_revenue#1060L]\n",
            "+- Project [city#117, amount#96]\n",
            "   +- InMemoryRelation [order_id#90, city#117, product#118, amount#96, order_date#97, status#119], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "         +- AdaptiveSparkPlan isFinalPlan=true\n",
            "            +- == Final Plan ==\n",
            "               ResultQueryStage 1\n",
            "               +- *(3) Filter (isnotnull(status#821) AND (status#821 = Completed))\n",
            "                  +- SortAggregate(key=[order_id#90], functions=[first(city#117, false), first(product#118, false), first(amount#96, false), first(order_date#97, false), first(status#119, false)], output=[order_id#90, city#813, product#815, amount#817, order_date#819, status#821])\n",
            "                     +- *(2) Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                        +- ShuffleQueryStage 0\n",
            "                           +- Exchange hashpartitioning(order_id#90, 200), ENSURE_REQUIREMENTS, [plan_id=1703]\n",
            "                              +- SortAggregate(key=[order_id#90], functions=[partial_first(city#117, false), partial_first(product#118, false), partial_first(amount#96, false), partial_first(order_date#97, false), partial_first(status#119, false)], output=[order_id#90, first#832, valueSet#833, first#834, valueSet#835, first#836, valueSet#837, first#838, valueSet#839, first#840, valueSet#841])\n",
            "                                 +- *(1) Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                                    +- *(1) Project [order_id#90, initcap(trim(city#91, None)) AS city#117, initcap(trim(product#92, None)) AS product#118, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END AS amount#96, coalesce(cast(gettimestamp(order_date#94, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#97, initcap(trim(status#95, None)) AS status#119]\n",
            "                                       +- *(1) Filter atleastnnonnulls(1, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END)\n",
            "                                          +- *(1) Scan ExistingRDD[order_id#90,city#91,product#92,amount#93,order_date#94,status#95]\n",
            "            +- == Initial Plan ==\n",
            "               Filter (isnotnull(status#821) AND (status#821 = Completed))\n",
            "               +- SortAggregate(key=[order_id#90], functions=[first(city#117, false), first(product#118, false), first(amount#96, false), first(order_date#97, false), first(status#119, false)], output=[order_id#90, city#813, product#815, amount#817, order_date#819, status#821])\n",
            "                  +- Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                     +- Exchange hashpartitioning(order_id#90, 200), ENSURE_REQUIREMENTS, [plan_id=1664]\n",
            "                        +- SortAggregate(key=[order_id#90], functions=[partial_first(city#117, false), partial_first(product#118, false), partial_first(amount#96, false), partial_first(order_date#97, false), partial_first(status#119, false)], output=[order_id#90, first#832, valueSet#833, first#834, valueSet#835, first#836, valueSet#837, first#838, valueSet#839, first#840, valueSet#841])\n",
            "                           +- Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                              +- Project [order_id#90, initcap(trim(city#91, None)) AS city#117, initcap(trim(product#92, None)) AS product#118, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END AS amount#96, coalesce(cast(gettimestamp(order_date#94, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#97, initcap(trim(status#95, None)) AS status#119]\n",
            "                                 +- Filter atleastnnonnulls(1, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END)\n",
            "                                    +- Scan ExistingRDD[order_id#90,city#91,product#92,amount#93,order_date#94,status#95]\n",
            "\n",
            "== Physical Plan ==\n",
            "AdaptiveSparkPlan isFinalPlan=true\n",
            "+- == Final Plan ==\n",
            "   ResultQueryStage 2\n",
            "   +- *(2) HashAggregate(keys=[city#117], functions=[sum(amount#96)], output=[city#117, total_revenue#1060L])\n",
            "      +- AQEShuffleRead coalesced\n",
            "         +- ShuffleQueryStage 1\n",
            "            +- Exchange hashpartitioning(city#117, 200), ENSURE_REQUIREMENTS, [plan_id=1788]\n",
            "               +- *(1) HashAggregate(keys=[city#117], functions=[partial_sum(amount#96)], output=[city#117, sum#1159L])\n",
            "                  +- TableCacheQueryStage 0\n",
            "                     +- InMemoryTableScan [city#117, amount#96]\n",
            "                           +- InMemoryRelation [order_id#90, city#117, product#118, amount#96, order_date#97, status#119], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                                 +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                                 +- == Final Plan ==\n",
            "                                    ResultQueryStage 1\n",
            "                                    +- *(3) Filter (isnotnull(status#821) AND (status#821 = Completed))\n",
            "                                       +- SortAggregate(key=[order_id#90], functions=[first(city#117, false), first(product#118, false), first(amount#96, false), first(order_date#97, false), first(status#119, false)], output=[order_id#90, city#813, product#815, amount#817, order_date#819, status#821])\n",
            "                                          +- *(2) Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                                             +- ShuffleQueryStage 0\n",
            "                                                +- Exchange hashpartitioning(order_id#90, 200), ENSURE_REQUIREMENTS, [plan_id=1703]\n",
            "                                                   +- SortAggregate(key=[order_id#90], functions=[partial_first(city#117, false), partial_first(product#118, false), partial_first(amount#96, false), partial_first(order_date#97, false), partial_first(status#119, false)], output=[order_id#90, first#832, valueSet#833, first#834, valueSet#835, first#836, valueSet#837, first#838, valueSet#839, first#840, valueSet#841])\n",
            "                                                      +- *(1) Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                                                         +- *(1) Project [order_id#90, initcap(trim(city#91, None)) AS city#117, initcap(trim(product#92, None)) AS product#118, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END AS amount#96, coalesce(cast(gettimestamp(order_date#94, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#97, initcap(trim(status#95, None)) AS status#119]\n",
            "                                                            +- *(1) Filter atleastnnonnulls(1, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END)\n",
            "                                                               +- *(1) Scan ExistingRDD[order_id#90,city#91,product#92,amount#93,order_date#94,status#95]\n",
            "                                 +- == Initial Plan ==\n",
            "                                    Filter (isnotnull(status#821) AND (status#821 = Completed))\n",
            "                                    +- SortAggregate(key=[order_id#90], functions=[first(city#117, false), first(product#118, false), first(amount#96, false), first(order_date#97, false), first(status#119, false)], output=[order_id#90, city#813, product#815, amount#817, order_date#819, status#821])\n",
            "                                       +- Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                                          +- Exchange hashpartitioning(order_id#90, 200), ENSURE_REQUIREMENTS, [plan_id=1664]\n",
            "                                             +- SortAggregate(key=[order_id#90], functions=[partial_first(city#117, false), partial_first(product#118, false), partial_first(amount#96, false), partial_first(order_date#97, false), partial_first(status#119, false)], output=[order_id#90, first#832, valueSet#833, first#834, valueSet#835, first#836, valueSet#837, first#838, valueSet#839, first#840, valueSet#841])\n",
            "                                                +- Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                                                   +- Project [order_id#90, initcap(trim(city#91, None)) AS city#117, initcap(trim(product#92, None)) AS product#118, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END AS amount#96, coalesce(cast(gettimestamp(order_date#94, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#97, initcap(trim(status#95, None)) AS status#119]\n",
            "                                                      +- Filter atleastnnonnulls(1, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END)\n",
            "                                                         +- Scan ExistingRDD[order_id#90,city#91,product#92,amount#93,order_date#94,status#95]\n",
            "+- == Initial Plan ==\n",
            "   HashAggregate(keys=[city#117], functions=[sum(amount#96)], output=[city#117, total_revenue#1060L])\n",
            "   +- Exchange hashpartitioning(city#117, 200), ENSURE_REQUIREMENTS, [plan_id=1762]\n",
            "      +- HashAggregate(keys=[city#117], functions=[partial_sum(amount#96)], output=[city#117, sum#1159L])\n",
            "         +- InMemoryTableScan [city#117, amount#96]\n",
            "               +- InMemoryRelation [order_id#90, city#117, product#118, amount#96, order_date#97, status#119], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
            "                     +- AdaptiveSparkPlan isFinalPlan=true\n",
            "                     +- == Final Plan ==\n",
            "                        ResultQueryStage 1\n",
            "                        +- *(3) Filter (isnotnull(status#821) AND (status#821 = Completed))\n",
            "                           +- SortAggregate(key=[order_id#90], functions=[first(city#117, false), first(product#118, false), first(amount#96, false), first(order_date#97, false), first(status#119, false)], output=[order_id#90, city#813, product#815, amount#817, order_date#819, status#821])\n",
            "                              +- *(2) Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                                 +- ShuffleQueryStage 0\n",
            "                                    +- Exchange hashpartitioning(order_id#90, 200), ENSURE_REQUIREMENTS, [plan_id=1703]\n",
            "                                       +- SortAggregate(key=[order_id#90], functions=[partial_first(city#117, false), partial_first(product#118, false), partial_first(amount#96, false), partial_first(order_date#97, false), partial_first(status#119, false)], output=[order_id#90, first#832, valueSet#833, first#834, valueSet#835, first#836, valueSet#837, first#838, valueSet#839, first#840, valueSet#841])\n",
            "                                          +- *(1) Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                                             +- *(1) Project [order_id#90, initcap(trim(city#91, None)) AS city#117, initcap(trim(product#92, None)) AS product#118, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END AS amount#96, coalesce(cast(gettimestamp(order_date#94, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#97, initcap(trim(status#95, None)) AS status#119]\n",
            "                                                +- *(1) Filter atleastnnonnulls(1, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END)\n",
            "                                                   +- *(1) Scan ExistingRDD[order_id#90,city#91,product#92,amount#93,order_date#94,status#95]\n",
            "                     +- == Initial Plan ==\n",
            "                        Filter (isnotnull(status#821) AND (status#821 = Completed))\n",
            "                        +- SortAggregate(key=[order_id#90], functions=[first(city#117, false), first(product#118, false), first(amount#96, false), first(order_date#97, false), first(status#119, false)], output=[order_id#90, city#813, product#815, amount#817, order_date#819, status#821])\n",
            "                           +- Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                              +- Exchange hashpartitioning(order_id#90, 200), ENSURE_REQUIREMENTS, [plan_id=1664]\n",
            "                                 +- SortAggregate(key=[order_id#90], functions=[partial_first(city#117, false), partial_first(product#118, false), partial_first(amount#96, false), partial_first(order_date#97, false), partial_first(status#119, false)], output=[order_id#90, first#832, valueSet#833, first#834, valueSet#835, first#836, valueSet#837, first#838, valueSet#839, first#840, valueSet#841])\n",
            "                                    +- Sort [order_id#90 ASC NULLS FIRST], false, 0\n",
            "                                       +- Project [order_id#90, initcap(trim(city#91, None)) AS city#117, initcap(trim(product#92, None)) AS product#118, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END AS amount#96, coalesce(cast(gettimestamp(order_date#94, yyyy-MM-dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd-MM-yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, dd/MM/yyyy, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date), cast(gettimestamp(order_date#94, yyyy/MM/dd, TimestampType, try_to_timestamp, Some(Etc/UTC), false) as date)) AS order_date#97, initcap(trim(status#95, None)) AS status#119]\n",
            "                                          +- Filter atleastnnonnulls(1, CASE WHEN RLIKE(amount#93, ^[0-9]+$) THEN cast(amount#93 as int) END)\n",
            "                                             +- Scan ExistingRDD[order_id#90,city#91,product#92,amount#93,order_date#94,status#95]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The explain(True) output shows InMemoryRelation and InMemoryTableScan [city#117, amount#96], which means Spark read the data directly from the cached DataFrame instead of recomputing all previous transformations for the completed_orders dataframe.\\\n",
        "This helps in saving time and resources as Spark only scans the needed columns from memory and runs the aggregation faster, avoiding expensive reprocessing of the original data."
      ],
      "metadata": {
        "id": "tQs9jRGo-mnr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UNM9E8Ik80Um"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}